# -*- coding: utf-8 -*-
"""densenet201.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EYiYHz397WoZSSX8DzjVGn4uyIxje4dl
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Load Libraries"""

# Commented out IPython magic to ensure Python compatibility.
# Import packages
# %config Completer.use_jedi = False

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle

from keras.utils.vis_utils import plot_model


from sklearn.model_selection import train_test_split 
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from tensorflow.keras.applications import Xception
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import cv2
import albumentations as A
from keras.models import Sequential, Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import gc
from tensorflow.keras.utils import to_categorical
from random import seed
from random import randint
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold
from keras.models import model_from_json
from sklearn.metrics import cohen_kappa_score, roc_auc_score, roc_curve,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

"""# Load data"""

train_df = pd.read_csv('/content/drive/MyDrive/EMOCNN/fer2013.csv')
train_df.head()

"""## Organize Labels¶

"""

# Convert the string of pixels to an array
train_df['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in train_df['pixels']]

# Assign the emotions to the corresponding number and apply them to the DataFrame
emotion_cat = {0:'Anger', 1:'Disgust', 2:'Fear', 3:'Happiness', 4: 'Sadness', 5: 'Surprise', 6: 'Neutral'}

#train_df['emotion'] = train_df['emotion'].apply(lambda x: emotion_cat[x])

# Create variables for pixels and labels
pixels = np.concatenate(train_df['pixels'])
labels = train_df.emotion.values

emotion_prop = (train_df.emotion.value_counts() / len(train_df)).to_frame().sort_index(ascending=True)

# Create a bar chart for the labels
palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']

plt.figure(figsize=[12,6])

plt.bar(x=emotion_prop.index, height=emotion_prop['emotion'], color=palette, edgecolor='black')
    
plt.xlabel('Emotion')
plt.ylabel('Proportion')
plt.title('Emotion Label Proportions')
plt.show()

"""## Converting strings to array¶

"""

# Print the shape of both arrays
print(pixels.shape)
print(labels.shape)

# Split the data into a training and validation set
X_train, X_valid, y_train, y_valid = train_test_split(
    pixels, labels, test_size=0.15, stratify=labels, random_state=1
)


# View the shapes of the data sets
print('X_train Shape:', X_train.shape)
print('y_train Shape:', y_train.shape)
print()
print('X_valid Shape:', X_valid.shape)
print('y_valid Shape:', y_valid.shape)

# Standardize the pixel values between 0 and 1
Xs_train = X_train / 255
Xs_valid = X_valid / 255

"""## Using random data augmentation"""

# Create an image generator for augmentation
train_datagen = ImageDataGenerator(
    rotation_range = 30,
    width_shift_range = 0.2, 
    height_shift_range = 0.2, 
    zoom_range = 0.2, 
    horizontal_flip = True, 
    fill_mode = 'nearest'
)

train_loader = train_datagen.flow(Xs_train, y_train, batch_size=64)

"""## Create model"""

def Dense_Model():
  input_shape_densenet = (48, 48, 3)
  densenet_model = keras.applications.DenseNet201(
      include_top=False,
      weights="imagenet",
      input_tensor=None,
      input_shape=input_shape_densenet
  )
  
  densenet_model.trainable = True


  input = keras.Input(shape=(48, 48, 3))
  layer = densenet_model(inputs=input)
  layer = keras.layers.Flatten()(layer)
  layer = keras.layers.Dense(units=512, activation='relu')(layer)
  layer = keras.layers.Dropout(0.4)(layer)
  layer = keras.layers.Dense(units=256, activation='relu')(layer)
  layer = keras.layers.Dropout(0.4)(layer)
  layer = keras.layers.Dense(units=128, activation='relu')(layer)
  layer = keras.layers.Dropout(0.3)(layer)
  output = keras.layers.Dense(units=7, activation='softmax')(layer)

  model = keras.models.Model(inputs=input, outputs=output)
  return model

model = Dense_Model()

np.random.seed(51)
tf.random.set_seed(51)

#cnn = DenseNet
model.summary()

plot_model(model, to_file='/content/drive/MyDrive/EMOCNN/DenseNet_model.png', show_shapes=True, show_layer_names=True)

"""## Train the model"""

# Set up the optimizer
opt = tf.keras.optimizers.Adam(0.001)
model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Training Run #1
# h1 = model.fit(train_loader, 
#              batch_size=64, 
#              epochs=100, 
#              validation_data=(Xs_valid, y_valid), verbose=1)

# Save history and view plots of loss and accuracy
history = h1.history
n_epochs = len(history['loss'])

plt.figure(figsize=[10,4])
plt.subplot(1,2,1)
plt.plot(range(1, n_epochs+1), history['loss'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.show()

# save model structure in jason file
model_json = model.to_json()
with open("/content/drive/MyDrive/EMOCNN/DenseNet201.json", "w") as json_file:
    json_file.write(model_json)

# save trained model weight in .h5 file
model.save_weights('/content/drive/MyDrive/EMOCNN/DenseNet201.h5')

"""## Training Run 2¶

"""

# Update the learning rate
tf.keras.backend.set_value(model.optimizer.learning_rate, 0.0001)

# Commented out IPython magic to ensure Python compatibility.
# %%time 
# 
# # Training Run #2
# h2 = model.fit(train_loader, 
#              batch_size=64, 
#              epochs=40, 
#              validation_data=(Xs_valid, y_valid), verbose=1)

# Save history and view plots of loss and accuracy
for k in history.keys():
    history[k] += h2.history[k]

epoch_range = range(1, len(history['loss'])+1)

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(epoch_range, history['loss'], label='Training')
plt.plot(epoch_range, history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(epoch_range, history['accuracy'], label='Training')
plt.plot(epoch_range, history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.tight_layout()
plt.show()

"""## Training Run 3¶

"""

# Update the learning rate
tf.keras.backend.set_value(model.optimizer.learning_rate, 0.00001)

# Commented out IPython magic to ensure Python compatibility.
# %%time 
# 
# # Training Run #3
# h3 = model.fit(train_loader, 
#              batch_size=64, 
#              epochs=20, 
#              validation_data=(Xs_valid, y_valid), verbose=1)

# Save history and view plots of loss and accuracy
for k in history.keys():
    history[k] += h3.history[k]

epoch_range = range(1, len(history['loss'])+1)

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(epoch_range, history['loss'], label='Training')
plt.plot(epoch_range, history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(epoch_range, history['accuracy'], label='Training')
plt.plot(epoch_range, history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.tight_layout()
plt.show()

"""#save 2nd model after 20 last epochs"""

# save model structure in jason file
model_json = xception.to_json()
with open("/content/drive/MyDrive/EMOCNN/emotion_model20.json", "w") as json_file:
    json_file.write(model_json)

# save trained model weight in .h5 file
xception.save_weights('/content/drive/MyDrive/EMOCNN/emotion_model20.h5')

# Save the model
xception.save('/content/drive/MyDrive/EMOCNN/fer_XceptionV320.h5')
pickle.dump(history, open(f'/content/drive/MyDrive/EMOCNN/fer_XceptionV320.pkl', 'wb'))